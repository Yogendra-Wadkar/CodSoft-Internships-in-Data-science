# Data Science Internship at CodSoft

## Project Overview

This repository contains the code and documentation for the three machine learning tasks completed during the internship at CodeSoft. The tasks include Titanic Survival Prediction, Iris Flowers Classifier, and Advertising Sales Prediction.

### 1. Titanic Survival Prediction

#### Problem Statement:
Develop a predictive model to determine the likelihood of survival for passengers on the Titanic based on available features. Perform exploratory data analysis (EDA), handle null values and outliers, use LabelEncoder, and Standard Scaler for feature engineering. Train models using logistic regression and decision tree algorithms, with decision tree hyperparameter tuning for enhanced accuracy.

#### Key Steps:
- **EDA:** Handle null values and outliers using mean, mode, median, boxplot, and IQR.
- **Feature Engineering:** Use LabelEncoder and Standard Scaler.
- **Model Training:** Logistic regression and decision tree algorithms, with hyperparameter tuning for decision tree.

#### Conclusion:
The decision tree algorithm, with hyperparameter tuning, outperformed other models, achieving the highest accuracy for predicting Titanic survival.

### 2. Iris Flowers Classifier

#### Problem Statement:
Build a machine learning model to classify iris flowers into three species. Use logistic regression and decision tree algorithms, evaluate performance metrics, and perform hyperparameter tuning. Visualize characteristics distinguishing iris species.

#### Key Steps:
- **EDA:** Detect outliers using boxplot and IQR.
- **Model Training:** Logistic regression and decision tree algorithms, with hyperparameter tuning for decision tree.

#### Conclusion:
The decision tree algorithm, with hyperparameter tuning, demonstrated superior performance, achieving high accuracy on both training and testing data.

### 3. Advertising Sales Prediction

#### Problem Statement:
Build a regression model to predict sales based on advertising spending. Conduct EDA, check Pearson's correlation, and variance inflation factor. Train linear regression and decision tree regression models, evaluate performance, and explore nonlinear relationships.

#### Key Steps:
- **EDA:** Detect outliers using boxplot and IQR.
- **Feature Selection:** Check Pearson's correlation and variance inflation factor.
- **Model Training:** Linear regression and decision tree regression algorithms, with hyperparameter tuning for decision tree.

#### Conclusion:
Both linear regression and decision tree regression algorithms performed well, with decision tree regression achieving slightly higher accuracy, indicating its suitability for the task.

## Additional Details

### Web Details

For additional insights, visualizations, and detailed analysis, refer to the Jupyter notebooks available in the `notebooks` directory. The detailed documentation and code comments provide a comprehensive understanding of the implemented solutions.

### Acknowledgments

Special thanks to CodeSoft for providing the opportunity to work on these impactful machine learning projects.

